# SHREYAS DEVDATTA KHOBRAGADE  
Worcester, MA | +1-774-525-2402 | skhobragade@wpi.edu  
LinkedIn | GitHub | Portfolio  

---

## SUMMARY
Robotics and Perception Engineer with a strong applied research background and hands-on experience building real-time autonomous systems. Experienced in computer vision, perception pipelines, motion planning, and sim-to-real deployment for aerial and ground robots. Proven ability to translate research ideas into production-ready systems running on embedded hardware under real-world constraints.

---

## EDUCATION

**Worcester Polytechnic Institute (WPI)** — Worcester, MA  
**M.S. Robotics Engineering**, GPA: 4.0 / 4.0  
*Aug 2024 – May 2026*  
- Awards: Dr. Glenn Yee Graduate Student Project Award, EDU Bridge Scholarship  
- Coursework: Computer Vision, Motion Planning, Reinforcement Learning, Autonomous Aerial Robotics  

**Visvesvaraya National Institute of Technology (VNIT)** — Nagpur, India  
**B.Tech. Electronics and Communication Engineering**, GPA: 8.26 / 10  
*Aug 2018 – May 2022*  

---

## TECHNICAL SKILLS

**Programming Languages:** Python, C, C++, MATLAB  
**Robotics & Perception:** ROS2, OMPL, OpenCV, NumPy, PyTorch, TensorFlow, scikit-learn  
**Autonomy & AI:** Reinforcement Learning (PPO), Motion Planning (RRT, Kinodynamic RRT), Visual-Inertial Odometry  
**Simulation & Tools:** Isaac Sim, Blender, MATLAB/Simulink, LaTeX  
**Embedded & Hardware:** NVIDIA Jetson Orin Nano, Raspberry Pi, Arduino, ESP32, Pixhawk / PX4  
**Other:** Linux, Git, Data Visualization, Model Training & Evaluation  

---

## WORK EXPERIENCE

### PeAR Lab, Worcester Polytechnic Institute — Graduate Researcher  
*Jul 2025 – Present*
- Designed and implemented a complete **sim-to-real autonomy pipeline** for aerial robots operating in **zero-light and GPS-denied environments**.
- Built a **perception system using structured lighting and coded apertures** for dense depth estimation, enabling robust obstacle avoidance without ambient illumination.
- Trained and deployed deep learning models (DenseNet-121) for depth inference, achieving **real-time performance (15+ FPS)** on **Jetson Orin Nano**.
- Integrated perception outputs with motion planning and control for closed-loop autonomous navigation in cluttered environments.
- Focused on system reliability, latency constraints, and deployment on embedded hardware.
- Developing learning-based low-light navigation using structured lighting with event cameras for sim-to-real transfer.

---

### Jio Platforms Limited — 5G Software Engineer (R&D)  
*Jun 2022 – May 2024*
- Developed and modified **high-performance C/C++ networking software** within the Vector Packet Processing (VPP) framework.
- Implemented shared-memory mechanisms to store **User Plane Function (UPF)** statistics, enabling improved real-time monitoring and faster debugging of system crashes.
- Migrated and refactored UPF components to support newer VPP versions, improving system stability, performance, and maintainability.
- Worked on performance-critical, low-latency systems with strict reliability requirements.

---

## PUBLICATIONS

- **AsterNav: Autonomous Aerial Robot Navigation in Darkness Using Passive Computation**,  
  *IEEE Robotics and Automation Letters (RA-L), 2026 (Early Access)*  
- **Real-time Track and Anomaly Detection in Complex Railway Environments**,  
  *International Conference on Communication, Embedded Systems, Machine Learning and Signal Processing (PCEMS), 2022*  

---

## PROJECTS

### Einstein Vision: Advanced Visualizations for Self-Driving Cars  
*Python, PyTorch, OpenCV, Blender* | GitHub  
*Jan 2025 – May 2025*
- Developed perception and visualization pipelines for autonomous driving scenarios, integrating **object detection, lane detection, optical flow, and depth estimation**.
- Integrated models including Mask R-CNN, YOLO, Detic, Depth Anything V2, and RAFT to detect and track vehicles, pedestrians, lanes, and traffic signals.
- Generated high-fidelity rendered videos across **13 driving sequences**, reducing perception ambiguities by **15–20%** through hybrid deep learning and classical heuristics.

---

### Deep Visual-Inertial Odometry  
*Python, PyTorch, Blender* | GitHub  
*Jan 2025 – May 2025*
- Designed a **visual-inertial odometry (VIO) pipeline** combining CNN-based visual feature extraction with LSTM-based IMU fusion.
- Trained models using synthetic datasets generated in Blender across **25 trajectory types** and multiple noise profiles.
- Achieved a **28% reduction in absolute trajectory error RMSE** compared to baseline approaches.

---

### Optimizing Mixed-Autonomy Traffic Using Reinforcement Learning  
*Python, PPO, SUMO, Flow*  
*Oct 2024 – Dec 2024*
- Developed a reinforcement learning framework using **Proximal Policy Optimization (PPO)** to improve traffic flow in mixed human-autonomous driving scenarios.
- Designed reward functions incorporating efficiency and fairness constraints.
- Demonstrated improved throughput, average speed, and fairness across multiple bottleneck scenarios.

---

### Real-Time Motion Planning for Drones in Unknown Environments  
*ROS2, OctoMap, EDT3D, C++*  
*Oct 2024 – Dec 2024*
- Built a real-time 3D motion planning framework for aerial robots operating in unknown and cluttered environments.
- Integrated **OctoMap** for global mapping and **EDT3D** for local collision checking.
- Implemented a **kinodynamic RRT-based planner** accounting for vehicle dynamics and obstacle avoidance.
- Validated collision-free navigation performance in simulation.

---

## KEYWORDS
Robotics Engineering, Computer Vision, Perception, Autonomy, ROS2, Motion Planning, Reinforcement Learning, SLAM, Visual-Inertial Odometry, Embedded Systems, Jetson, Autonomous Drones, Real-Time Systems, Sim-to-Real, Python, C++
